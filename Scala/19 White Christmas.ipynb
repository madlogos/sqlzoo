{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# White Christmas\n",
    "\n",
    "## HadCET\n",
    "The [HadCET](http://www.metoffice.gov.uk/hadobs/hadcet/) data is \"the longest available instrumental record of temperature in the world\", currently available from the UK Met Office. It provides the daily mean temperature for the centre of England since 1772.\n",
    "\n",
    "From that table you can see that the mean daily temperature for 1st January 2001 was recorded as 40 meaning 4.0°C, the temperature for 2nd January 2001 has 77 which translates to 7.7°C\n",
    "\n",
    "The February temperatures are in the m2 column, notice that -999 has been entered for invalid cells such as 31 Feb 2001.\n",
    "\n",
    "```\n",
    "+------+----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+\n",
    "| yr   | dy |  m1 |  m2 |  m3 |  m4 |  m5 |  m6 |  m7 |  m8 |  m9 | m10 | m11 | m12 |\n",
    "+------+----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+\n",
    "| 2001 |  1 |  40 |  11 |   9 | 112 |  87 | 131 | 185 | 180 | 150 | 151 |  91 |  98 |\n",
    "| 2001 |  2 |  77 |  32 |  -4 | 114 |  99 | 126 | 207 | 163 | 168 | 143 |  99 |  29 |\n",
    "| 2001 |  3 |  52 |  66 |  -3 |  84 | 105 | 100 | 209 | 166 | 153 | 142 |  87 |  55 |\n",
    "| 2001 |  4 |  50 |  57 |   5 |  69 |  72 | 130 | 219 | 151 | 134 | 139 |  90 |  73 |\n",
    "| 2001 |  5 |  47 |  68 |  12 |  71 |  82 | 136 | 217 | 161 | 139 | 159 |  75 |  82 |\n",
    "| 2001 |  6 |  43 |  83 |  57 |  90 |  76 | 135 | 201 | 173 | 141 | 142 |  95 |  46 |\n",
    "| 2001 |  7 |  49 |  85 |  86 |  69 |  90 | 110 | 185 | 161 | 153 | 128 | 112 |  62 |\n",
    "| 2001 |  8 |  51 |  34 |  87 |  71 |  93 | 102 | 163 | 155 | 147 | 127 |  50 |  40 |\n",
    "| 2001 |  9 |  22 |  21 |  90 | 101 | 102 | 101 | 157 | 141 | 121 | 132 |  33 |  16 |\n",
    "| 2001 | 10 |  23 |  51 | 102 |  96 | 147 | 110 | 160 | 152 | 119 | 125 |  44 |  19 |\n",
    "| 2001 | 11 |  29 |  81 | 101 |  72 | 172 | 106 | 141 | 152 | 142 | 150 |  78 |  20 |\n",
    "| 2001 | 12 |  40 |  79 |  60 |  74 | 168 | 138 | 144 | 171 | 142 | 153 | 101 |  46 |\n",
    "| 2001 | 13 |  31 |  40 |  57 |  57 | 165 | 148 | 143 | 195 | 124 | 160 |  53 |  47 |\n",
    "| 2001 | 14 |  24 |  35 |  64 |  75 | 118 | 144 | 132 | 205 | 124 | 155 |  40 |  15 |\n",
    "| 2001 | 15 |  18 |  44 |  53 |  91 | 120 | 153 | 127 | 210 | 129 | 154 |  43 |  13 |\n",
    "| 2001 | 16 | -12 |  46 |  54 |  73 | 128 | 138 | 133 | 176 | 125 | 117 |  55 |  23 |\n",
    "| 2001 | 17 |  -9 |  21 |  26 |  52 |  89 | 123 | 143 | 157 | 109 | 138 |  83 |  20 |\n",
    "| 2001 | 18 |  -5 |   3 |  28 |  44 | 101 | 128 | 149 | 167 | 124 | 147 |  73 |  38 |\n",
    "| 2001 | 19 |  -8 |  26 |  20 |  54 | 119 | 160 | 137 | 181 | 129 | 113 |  63 |  48 |\n",
    "| 2001 | 20 |  -5 |  36 |  22 |  54 | 130 | 156 | 146 | 169 | 138 | 135 |  67 |  26 |\n",
    "| 2001 | 21 |  13 |  62 |  26 |  52 | 129 | 140 | 153 | 159 | 116 | 104 |  96 |  41 |\n",
    "| 2001 | 22 |  45 |  73 |  60 |  64 | 131 | 139 | 169 | 179 | 119 | 118 |  91 |  12 |\n",
    "| 2001 | 23 |  69 |  49 |  77 |  84 | 150 | 160 | 170 | 179 | 103 | 137 |  48 |  18 |\n",
    "| 2001 | 24 |  69 |  27 |  68 |  68 | 157 | 173 | 155 | 191 | 127 | 130 |  68 |  34 |\n",
    "| 2001 | 25 |  48 |  14 |  49 |  85 | 137 | 191 | 181 | 193 | 123 | 124 | 115 |  45 |\n",
    "| 2001 | 26 |  47 |  27 |  38 |  90 | 157 | 219 | 184 | 171 | 112 | 124 |  51 |  27 |\n",
    "| 2001 | 27 |  40 |  27 |  50 |  84 | 160 | 187 | 194 | 152 | 145 | 122 |  48 |  40 |\n",
    "| 2001 | 28 |  11 |  23 |  70 |  99 | 176 | 170 | 206 | 143 | 166 | 116 |  76 |  43 |\n",
    "| 2001 | 29 |  20 |-999 |  66 |  76 | 160 | 177 | 230 | 149 | 168 | 106 |  96 |  18 |\n",
    "| 2001 | 30 |  25 |-999 |  83 |  80 | 149 | 170 | 201 | 154 | 141 | 140 | 124 |  15 |\n",
    "| 2001 | 31 |  40 |-999 | 100 |-999 | 130 |-999 | 192 | 146 |-999 | 101 |-999 |  -4 |\n",
    "| 2002 |  1 | -18 |  86 |  45 | 113 |  93 | 143 | 131 | 161 | 126 | 145 | 114 |  87 |\n",
    "| 2002 |  2 | -18 | 109 |  31 | 100 |  84 | 162 | 135 | 156 | 140 | 156 | 114 |  83 |\n",
    "+------+----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading spark-stubs, spark-hive\n",
      "Adding Hive conf dir /opt/hive/conf to classpath\n",
      "Creating SparkSession\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: No SLF4J providers were found.\n",
      "SLF4J: Defaulting to no-operation (NOP) logger implementation\n",
      "SLF4J: See https://www.slf4j.org/codes.html#noProviders for further details.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a target=\"_blank\" href=\"http://jupyter:4040\">Spark UI</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                  \n",
       "\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.log4j.{Level, Logger}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.types._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.functions._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.expressions.Window\n",
       "\n",
       "\u001b[39m\n",
       "\u001b[36mspark\u001b[39m: \u001b[32mSparkSession\u001b[39m = org.apache.spark.sql.SparkSession@583c500f"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`org.apache.spark::spark-sql:3.4.0`\n",
    "\n",
    "import org.apache.log4j.{Level, Logger}\n",
    "Logger.getLogger(\"org\").setLevel(Level.OFF)\n",
    "\n",
    "import org.apache.spark._\n",
    "import org.apache.spark.sql._\n",
    "import org.apache.spark.sql.types._\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.expressions.Window\n",
    "\n",
    "val spark = {\n",
    "    NotebookSparkSession.builder()\n",
    "    .progress(false)\n",
    "    .appName(\"app19\")\n",
    "    // .master(\"spark://192.168.31.31:7077\")\n",
    "    .master(\"local[*]\")\n",
    "    .config(\"spark.sql.warehouse.dir\", \n",
    "            \"hdfs://192.168.31.31:9000/user/hive/warehouse\") \n",
    "    .config(\"spark.cores.max\", \"4\") \n",
    "    .config(\"spark.executor.instances\", \"1\") \n",
    "    .config(\"spark.executor.cores\", \"2\") \n",
    "    .config(\"spark.executor.memory\", \"10g\") \n",
    "    .config(\"spark.shuffle.service.enabled\", \"false\") \n",
    "    .config(\"spark.dynamicAllocation.enabled\", \"false\") \n",
    "    .config(\"spark.sql.catalogImplementation\", \"hive\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", \"true\")\n",
    "    .config(\"spark.driver.allowMultipleContexts\", \"true\")\n",
    "    .getOrCreate()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mspark.implicits._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mspark.sqlContext.implicits._\n",
       "\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36msc\u001b[39m\n",
       "\u001b[36mhiveCxt\u001b[39m: \u001b[32msql\u001b[39m.\u001b[32mhive\u001b[39m.\u001b[32mHiveContext\u001b[39m = org.apache.spark.sql.hive.HiveContext@20d00dec"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spark.implicits._\n",
    "import spark.sqlContext.implicits._\n",
    "def sc = spark.sparkContext\n",
    "val hiveCxt = new org.apache.spark.sql.hive.HiveContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mclass\u001b[39m \u001b[36mRichDF\u001b[39m"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Credit to Aivean\n",
    "implicit class RichDF(val ds:DataFrame) {\n",
    "    def showHTML(limit: Int = 50, truncate: Int = 100) = {\n",
    "        import xml.Utility.escape\n",
    "        val data = ds.take(limit)\n",
    "        val header = ds.schema.fieldNames.toSeq        \n",
    "        val rows: Seq[Seq[String]] = data.map { row =>\n",
    "          row.toSeq.map {cell =>\n",
    "            val str = cell match {\n",
    "              case null => \"null\"\n",
    "              case binary: Array[Byte] => binary.map(\"%02X\".format(_)).mkString(\"[\", \" \", \"]\")\n",
    "              case array: Array[_] => array.mkString(\"[\", \", \", \"]\")\n",
    "              case seq: Seq[_] => seq.mkString(\"[\", \", \", \"]\")\n",
    "              case _ => cell.toString\n",
    "            }\n",
    "            if (truncate > 0 && str.length > truncate) {\n",
    "              // do not show ellipses for strings shorter than 4 characters.\n",
    "              if (truncate < 4) str.substring(0, truncate)\n",
    "              else str.substring(0, truncate - 3) + \"...\"\n",
    "            } else {\n",
    "              str\n",
    "            }\n",
    "          }: Seq[String]\n",
    "        }\n",
    "    publish.html(s\"\"\" <table>\n",
    "                <tr>\n",
    "                 ${header.map(h => s\"<th>${escape(h)}</th>\").mkString}\n",
    "                </tr>\n",
    "                ${rows.map {row =>\n",
    "                  s\"<tr>${row.map{c => s\"<td>${escape(c)}</td>\" }.mkString}</tr>\"\n",
    "                }.mkString}\n",
    "            </table>\n",
    "        \"\"\")\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mhadcet\u001b[39m: \u001b[32mDataFrame\u001b[39m = [yr: int, dy: int ... 12 more fields]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val hadcet = hiveCxt.table(\"sqlzoo.hadcet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Days, Months and Years\n",
    "The units are 10th of a degree Celcius. The columns are yr and dy for year and day of month. The next twelve columns are for January through to December.\n",
    "\n",
    "**Show the average daily temperature for August 10th 1964**\n",
    "\n",
    "```sql\n",
    "show create table hadcet\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       " <table>\n",
       "                <tr>\n",
       "                 <th>m8</th>\n",
       "                </tr>\n",
       "                <tr><td>139</td></tr>\n",
       "            </table>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(hadcet.filter((hadcet(\"yr\") === 1964) && (hadcet(\"dy\") === 10))\n",
    " .select(\"m8\").showHTML())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. preteen Dickens\n",
    "\n",
    "Charles Dickens is said to be responsible for the tradition of expecting snow at Christmas (Daily Telegraph)(http://www.telegraph.co.uk/topics/christmas/3933091/Dreaming-of-a-white-Christmas-Blame-the-nostalgia-of-Charles-Dickens-snowy-childhood.html). Show the temperature on Christmas day (25th December) for each year of his childhood. He was born in February 1812 - so he was 1 (more or less) in December 1812.\n",
    "\n",
    "**Show the twelve temperatures.**\n",
    "\n",
    "```sql\n",
    "SELECT yr-1811 as age FROM hadcet\n",
    "  WHERE yr BETWEEN 1812 and 1812+12 AND dy=25\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       " <table>\n",
       "                <tr>\n",
       "                 <th>age</th><th>m12</th>\n",
       "                </tr>\n",
       "                <tr><td>1</td><td>0</td></tr><tr><td>2</td><td>81</td></tr><tr><td>3</td><td>11</td></tr><tr><td>4</td><td>-8</td></tr><tr><td>5</td><td>30</td></tr><tr><td>6</td><td>-4</td></tr><tr><td>7</td><td>10</td></tr><tr><td>8</td><td>-8</td></tr><tr><td>9</td><td>-3</td></tr><tr><td>10</td><td>35</td></tr><tr><td>11</td><td>5</td></tr><tr><td>12</td><td>78</td></tr><tr><td>13</td><td>104</td></tr>\n",
       "            </table>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(hadcet.withColumn(\"age\", hadcet(\"yr\")-lit(1811))\n",
    " .filter((hadcet(\"yr\").between(1812, 1812+12)) && \n",
    "         (hadcet(\"dy\") === 25))\n",
    " .select(\"age\", \"m12\")\n",
    " .showHTML())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Minimum Temperature Before Christmas\n",
    "\n",
    "We declare a White Christmas if there was a day with an average temperature below zero between 21st and 25th of December.\n",
    "\n",
    "**For each age 1-12 show which years were a White Christmas. Show \"White Christmas\" or \"No snow\" for each age.**\n",
    "\n",
    "```sql\n",
    "SELECT yr-1811 as age FROM hadcet\n",
    "  WHERE yr BETWEEN 1812 and 1812+12 AND dy=25\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       " <table>\n",
       "                <tr>\n",
       "                 <th>age</th><th>lbl</th>\n",
       "                </tr>\n",
       "                <tr><td>1</td><td>No snow</td></tr><tr><td>2</td><td>No snow</td></tr><tr><td>3</td><td>White Christmas</td></tr><tr><td>4</td><td>White Christmas</td></tr><tr><td>5</td><td>White Christmas</td></tr><tr><td>6</td><td>White Christmas</td></tr><tr><td>7</td><td>White Christmas</td></tr><tr><td>8</td><td>White Christmas</td></tr><tr><td>9</td><td>White Christmas</td></tr><tr><td>10</td><td>No snow</td></tr><tr><td>11</td><td>White Christmas</td></tr><tr><td>12</td><td>No snow</td></tr>\n",
       "            </table>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(hadcet\n",
    " .filter((hadcet(\"yr\").between(1812, 1812+11)) && \n",
    "         (hadcet(\"dy\").between(21, 25) && \n",
    "          (hadcet(\"m12\") !== -999)))\n",
    " .groupBy(\"yr\")\n",
    " .agg(min(\"m12\").alias(\"m12\"))\n",
    " .withColumn(\"age\", hadcet(\"yr\")-lit(1811))\n",
    " .withColumn(\"lbl\", when(col(\"m12\")<0, lit(\"White Christmas\"))\n",
    "             .otherwise(lit(\"No snow\")))\n",
    " .select(\"age\", \"lbl\")\n",
    " .orderBy(\"age\")\n",
    " .showHTML())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. White Christmas Count\n",
    "\n",
    "A person\"s White Christmas Count (wcc) is the number of White Christmases they were exposed to as a child (between 3 and 12 inclusive assuming they were born at the beginning of the year and were about 1 year old on their first Christmas).\n",
    "\n",
    "Charles Dickens\"s wcc was 8.\n",
    "\n",
    "**List all the years and the wcc for children born in each year of the data set. Only show years where the wcc was at least 7.**\n",
    "\n",
    "```sql\n",
    "SELECT yr-1811 as age FROM hadcet\n",
    "  WHERE yr BETWEEN 1812 and 1812+12 AND dy=25\n",
    "```\n",
    "\n",
    "```\n",
    "+------+-----+\n",
    "| yob  | wcc |\n",
    "+------+-----+\n",
    "| 1805 |   7 |\n",
    "| 1806 |   7 |\n",
    "| 1807 |   7 |\n",
    "| 1808 |   8 |\n",
    "| 1809 |   9 |\n",
    "| 1810 |   8 |\n",
    "| 1811 |   8 |\n",
    "| 1812 |   8 |\n",
    "| 1813 |   7 |\n",
    "+------+-----+\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       " <table>\n",
       "                <tr>\n",
       "                 <th>yr</th><th>wcc</th>\n",
       "                </tr>\n",
       "                <tr><td>1809</td><td>7</td></tr><tr><td>1810</td><td>7</td></tr><tr><td>1811</td><td>8</td></tr><tr><td>1812</td><td>8</td></tr><tr><td>1813</td><td>7</td></tr>\n",
       "            </table>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mx\u001b[39m: \u001b[32mDataset\u001b[39m[\u001b[32mRow\u001b[39m] = [yr: int]\n",
       "\u001b[36my\u001b[39m: \u001b[32mDataFrame\u001b[39m = [yyr: int]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val x = (hadcet.select(\"yr\").distinct())\n",
    "val y = (hadcet.withColumn(\"wc\", (hadcet(\"m12\") < lit(0)).cast(\"integer\"))\n",
    "     .filter((hadcet(\"dy\").between(21, 25)) && (hadcet(\"m12\") !== -999))\n",
    "     .groupBy(\"yr\")\n",
    "     .agg(sum(\"wc\").alias(\"wc\"))\n",
    "     .filter(col(\"wc\") > 0)\n",
    "     .select($\"yr\".alias(\"yyr\")))\n",
    "\n",
    "(x.alias(\"x\")\n",
    " .join(y.alias(\"y\"))\n",
    " .filter((col(\"yyr\") >= col(\"yr\")+lit(2)) && \n",
    "         (col(\"yyr\") <= col(\"yr\")+lit(11)))\n",
    " .groupBy(\"yr\")\n",
    " .agg(count(\"yyr\").alias(\"wcc\"))\n",
    " .filter(col(\"wcc\") >= 7)\n",
    " .orderBy(\"yr\")\n",
    " .showHTML())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Climate Change\n",
    "\n",
    "Here are the average temperatures for August by decade. You decide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       " <table>\n",
       "                <tr>\n",
       "                 <th>decade</th><th>avg_temp</th>\n",
       "                </tr>\n",
       "                <tr><td>1770</td><td>163.16</td></tr><tr><td>1780</td><td>155.46</td></tr><tr><td>1790</td><td>157.57</td></tr><tr><td>1800</td><td>163.88</td></tr><tr><td>1810</td><td>148.09</td></tr><tr><td>1820</td><td>154.14</td></tr><tr><td>1830</td><td>153.44</td></tr><tr><td>1840</td><td>150.96</td></tr><tr><td>1850</td><td>157.73</td></tr><tr><td>1860</td><td>152.23</td></tr><tr><td>1870</td><td>157.23</td></tr><tr><td>1880</td><td>151.56</td></tr><tr><td>1890</td><td>155.58</td></tr><tr><td>1900</td><td>150.08</td></tr><tr><td>1910</td><td>156.4</td></tr><tr><td>1920</td><td>149.92</td></tr><tr><td>1930</td><td>162.53</td></tr><tr><td>1940</td><td>161.07</td></tr><tr><td>1950</td><td>156.98</td></tr><tr><td>1960</td><td>151.84</td></tr><tr><td>1970</td><td>159.85</td></tr><tr><td>1980</td><td>158.5</td></tr><tr><td>1990</td><td>167.7</td></tr><tr><td>2000</td><td>166.79</td></tr><tr><td>2010</td><td>160.07</td></tr>\n",
       "            </table>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(hadcet.withColumn(\"decade\", floor(hadcet(\"yr\") / 10) * 10)\n",
    " .filter(hadcet(\"m8\") !== -999)\n",
    " .groupBy(\"decade\")\n",
    " .agg(avg(\"m8\").alias(\"avg_temp\"))\n",
    " .withColumn(\"avg_temp\", round($\"avg_temp\", 2))\n",
    " .orderBy(\"decade\")\n",
    " .showHTML())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
